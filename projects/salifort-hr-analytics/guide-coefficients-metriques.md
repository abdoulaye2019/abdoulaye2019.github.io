# Guide Complet : Coefficients et M√©triques en Machine Learning

## üìö Table des mati√®res
1. [Les Coefficients de R√©gression Logistique](#coefficients)
2. [La Matrice de Confusion](#matrice)
3. [Les M√©triques de Performance](#metriques)
4. [Interpr√©tation Pratique pour le Projet Salifort](#interpretation)

---

## 1. Les Coefficients de R√©gression Logistique {#coefficients}

### üéØ Qu'est-ce qu'un coefficient ?

Un **coefficient** (ou poids) repr√©sente l'**influence** d'une variable sur la probabilit√© qu'un employ√© quitte l'entreprise. C'est comme mesurer la force de chaque facteur dans la d√©cision de d√©part.

### üìä Comment lire les coefficients ?

| Coefficient | Signification | Exemple |
|------------|---------------|---------|
| **Positif (+)** | ‚Üë La variable **augmente** le risque de d√©part | `number_project = +0.52` ‚Üí Plus de projets = plus de risque |
| **N√©gatif (-)** | ‚Üì La variable **diminue** le risque de d√©part | `satisfaction_level = -4.16` ‚Üí Plus de satisfaction = moins de risque |
| **Proche de 0** | La variable a **peu d'influence** | `work_accident = -0.02` ‚Üí Impact n√©gligeable |

### üîç Interpr√©tation avec Odds Ratio

Pour mieux comprendre l'impact, on utilise l'**Odds Ratio** = `e^(coefficient)`

**Formule :** `Odds Ratio = exp(coefficient)`

#### Exemple concret avec le projet Salifort :

```python
Coefficient de satisfaction_level = -4.16

Odds Ratio = e^(-4.16) = 0.0156 ‚âà 0.016

Interpr√©tation :
Pour chaque augmentation de 1 point de satisfaction (sur une √©chelle 0-1),
les chances de d√©part sont multipli√©es par 0.016, soit une R√âDUCTION de 98.4% !
```

### üìà Tableau des coefficients importants (Projet Salifort)

| Variable | Coefficient | Odds Ratio | Interpr√©tation |
|----------|-------------|------------|----------------|
| `satisfaction_level` | **-4.16** | 0.016 | ‚Üì 98.4% - **Forte r√©tention** avec satisfaction √©lev√©e |
| `last_evaluation` | **+3.45** | 31.50 | ‚Üë 3050% - √âvaluations √©lev√©es = risque de d√©part (talents chass√©s) |
| `number_project` | **+0.52** | 1.68 | ‚Üë 68% - Chaque projet suppl√©mentaire augmente le risque |
| `average_monthly_hours` | **+0.004** | 1.004 | ‚Üë 0.4% par heure - Impact faible mais cumulatif |
| `time_spend_company` | **+0.31** | 1.36 | ‚Üë 36% par ann√©e - Les v√©t√©rans partent plus |
| `work_accident` | **-1.44** | 0.24 | ‚Üì 76% - Accidents r√©duisent le d√©part (soutien post-accident?) |
| `promotion_last_5years` | **-1.31** | 0.27 | ‚Üì 73% - **Les promotions retiennent fortement** |

### üéì Pourquoi c'est important ?

**1. Identifier les leviers d'action**
- Satisfaction et promotions ont l'impact le plus fort
- Focus RH sur ces facteurs = meilleur ROI

**2. Quantifier l'effet**
- "Augmenter la satisfaction de 0.1 r√©duit le risque de 18%"
- Arguments chiffr√©s pour la direction

**3. D√©tecter les paradoxes**
- √âvaluations √©lev√©es ‚Üí d√©part (talents vol√©s)
- Accidents ‚Üí r√©tention (√† investiguer!)

---

## 2. La Matrice de Confusion {#matrice}

### üß© Qu'est-ce que c'est ?

La **matrice de confusion** est un tableau qui montre les **4 types de pr√©dictions** possibles :

```
                    PR√âDICTION
                  Rest√©    Parti
         Rest√©  [  TN   |   FP  ]  ‚Üê Vrai N√©gatif | Faux Positif
R√âALIT√â          |------+-------|
         Parti  [  FN   |   TP  ]  ‚Üê Faux N√©gatif | Vrai Positif
```

### üìä Les 4 cases expliqu√©es

#### ‚úÖ **TN (True Negative) - Vrai N√©gatif**
- **R√©alit√©** : L'employ√© est rest√©
- **Pr√©diction** : Le mod√®le pr√©dit qu'il reste
- **R√©sultat** : ‚úÖ **CORRECT !**
- **Exemple** : "Marc est satisfait, le mod√®le dit qu'il reste ‚Üí Marc reste effectivement"

#### ‚ùå **FP (False Positive) - Faux Positif**
- **R√©alit√©** : L'employ√© est rest√©
- **Pr√©diction** : Le mod√®le pr√©dit qu'il part
- **R√©sultat** : ‚ùå **ERREUR - Fausse alarme**
- **Cons√©quence** : RH perd du temps sur un employ√© qui n'allait pas partir
- **Exemple** : "Sophie est stress√©e temporairement, le mod√®le dit qu'elle part ‚Üí Sophie reste"

#### ‚ö†Ô∏è **FN (False Negative) - Faux N√©gatif**
- **R√©alit√©** : L'employ√© est parti
- **Pr√©diction** : Le mod√®le pr√©dit qu'il reste
- **R√©sultat** : ‚ùå **ERREUR - D√©part manqu√©**
- **Cons√©quence** : ‚ö†Ô∏è **GRAVE** - Perte de 50K$ de co√ªt de remplacement
- **Exemple** : "Thomas semblait bien, le mod√®le dit qu'il reste ‚Üí Thomas d√©missionne surprise!"

#### ‚úÖ **TP (True Positive) - Vrai Positif**
- **R√©alit√©** : L'employ√© est parti
- **Pr√©diction** : Le mod√®le pr√©dit qu'il part
- **R√©sultat** : ‚úÖ **CORRECT !**
- **Valeur** : Permet une intervention RH pr√©ventive
- **Exemple** : "Julie est √† risque, le mod√®le alerte ‚Üí Julie d√©missionne (on aurait pu agir)"

### üìà Matrice du Mod√®le Gradient Boosting (Projet Salifort)

```
                       PR√âDICTION
                    Rest√©      Parti
         Rest√©   [  1980   |    21   ]  ‚Üê 1980 correctes, 21 fausses alarmes
R√âALIT√â             |--------+---------|
         Parti   [   27    |   371   ]  ‚Üê 27 manqu√©es, 371 d√©tect√©es

Total : 2399 employ√©s dans le jeu de test
```

### üí° Lecture de la matrice

**Ligne 1 (Employ√©s rest√©s = 2001)**
- ‚úÖ 1980 bien identifi√©s comme "restent" (TN)
- ‚ùå 21 faussement identifi√©s comme "partent" (FP)
- **Taux de fausses alarmes** : 21/2001 = 1.05% (excellent!)

**Ligne 2 (Employ√©s partis = 398)**
- ‚ùå 27 manqu√©s par le mod√®le (FN) = **$1.35M de pertes**
- ‚úÖ 371 correctement d√©tect√©s (TP) = **$18.5M √©conomis√©s**
- **Taux de d√©tection** : 371/398 = 93.2% (recall)

### üéØ Objectifs selon le contexte

| Contexte | Priorit√© | M√©trique cl√© |
|----------|----------|--------------|
| **Salifort Motors** | ‚ö†Ô∏è Ne pas manquer de d√©parts | Maximiser **Recall** (TP √©lev√©) |
| **Spam Email** | üìß Ne pas bloquer vrais emails | Maximiser **Precision** (√©viter FP) |
| **Diagnostic M√©dical** | üè• Ne pas rater de maladies | Maximiser **Recall** (d√©tecter tout) |
| **Recommandation Produit** | üõçÔ∏è Ne pas irriter client | √âquilibrer Precision & Recall |

---

## 3. Les M√©triques de Performance {#metriques}

### üìä Les 5 m√©triques essentielles

#### 1Ô∏è‚É£ **Accuracy (Exactitude)**
```
Formule : (TP + TN) / Total
        = (Pr√©dictions correctes) / (Toutes les pr√©dictions)

Projet Salifort :
(371 + 1980) / 2399 = 98.1%
```

**Signification** : Le mod√®le est correct dans **98.1% des cas**

**‚ö†Ô∏è Attention** : M√©trique trompeuse si classes d√©s√©quilibr√©es !

**Exemple** : Si 90% des employ√©s restent, un mod√®le qui dit toujours "rest√©" aura 90% d'accuracy mais sera inutile.

---

#### 2Ô∏è‚É£ **Precision (Pr√©cision)**
```
Formule : TP / (TP + FP)
        = (Vrais positifs) / (Tous les positifs pr√©dits)

Projet Salifort :
371 / (371 + 21) = 371 / 392 = 94.6%
```

**Question r√©pondue** : "Quand le mod√®le dit qu'un employ√© va partir, quelle est la probabilit√© qu'il parte vraiment ?"

**Interpr√©tation** :
- **94.6%** des employ√©s flagg√©s comme "√† risque" partent effectivement
- Seulement **5.4%** de fausses alarmes
- RH peut faire confiance aux alertes !

**Cas d'usage** : Important quand les interventions sont co√ªteuses (temps RH limit√©)

---

#### 3Ô∏è‚É£ **Recall (Rappel / Sensibilit√©)**
```
Formule : TP / (TP + FN)
        = (Vrais positifs) / (Tous les positifs r√©els)

Projet Salifort :
371 / (371 + 27) = 371 / 398 = 93.2%
```

**Question r√©pondue** : "Sur tous les employ√©s qui partent, combien le mod√®le d√©tecte-t-il ?"

**Interpr√©tation** :
- Le mod√®le d√©tecte **93.2%** des d√©parts r√©els
- Seulement **27 d√©parts manqu√©s** sur 398 (6.8%)
- **$1.35M de pertes** vs **$18.5M √©conomis√©s**

**‚ö†Ô∏è CRITIQUE pour Salifort** :
- Manquer un d√©part co√ªte 50K$
- Fausse alarme co√ªte quelques heures RH
- **Priorit√© absolue : maximiser le Recall !**

---

#### 4Ô∏è‚É£ **F1-Score (Score F1)**
```
Formule : 2 √ó (Precision √ó Recall) / (Precision + Recall)
        = Moyenne harmonique de Precision et Recall

Projet Salifort :
2 √ó (0.946 √ó 0.932) / (0.946 + 0.932) = 94.2%
```

**Signification** : √âquilibre entre Precision et Recall

**Quand l'utiliser** :
- Classes d√©s√©quilibr√©es (23% d√©parts vs 77% rest√©s)
- On veut un compromis entre les deux m√©triques
- **Utile pour comparer des mod√®les**

**Note** : F1 p√©nalise les mod√®les d√©s√©quilibr√©s (bon Recall mais mauvaise Precision ou vice-versa)

---

#### 5Ô∏è‚É£ **ROC-AUC (Area Under the Curve)**
```
Formule : Aire sous la courbe ROC
        = Mesure globale de discrimination

Projet Salifort :
ROC-AUC = 0.981 (98.1%)
```

**Signification** : Capacit√© du mod√®le √† **distinguer** entre les deux classes

**√âchelle d'interpr√©tation** :
| ROC-AUC | Qualit√© | Interpr√©tation |
|---------|---------|----------------|
| **0.90 - 1.00** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excellent | Discrimination quasi-parfaite |
| **0.80 - 0.90** | ‚≠ê‚≠ê‚≠ê‚≠ê Tr√®s bon | Bonne s√©paration |
| **0.70 - 0.80** | ‚≠ê‚≠ê‚≠ê Acceptable | Mod√®le utilisable |
| **0.60 - 0.70** | ‚≠ê‚≠ê Faible | √Ä am√©liorer |
| **0.50 - 0.60** | ‚≠ê Tr√®s faible | Presque al√©atoire |
| **0.50** | ‚ùå Al√©atoire | Comme lancer une pi√®ce |

**Notre mod√®le : 0.981 = ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê EXCELLENT**

**Avantage** : Ind√©pendant du seuil de d√©cision (0.3, 0.5, 0.7...)

---

### üìä Tableau r√©capitulatif des m√©triques (Gradient Boosting)

| M√©trique | Valeur | Interpr√©tation Business |
|----------|--------|-------------------------|
| **Accuracy** | 98.1% | 98 pr√©dictions correctes sur 100 |
| **Precision** | 94.6% | 95% des alertes sont justifi√©es |
| **Recall** | 93.2% | 93% des d√©parts sont d√©tect√©s |
| **F1-Score** | 94.2% | Excellent √©quilibre global |
| **ROC-AUC** | 98.1% | Discrimination quasi-parfaite |

### üéØ Trade-off Precision vs Recall

```
Si on augmente le seuil (ex: 0.5 ‚Üí 0.7) :
‚îú‚îÄ Precision ‚Üë (moins de fausses alarmes)
‚îî‚îÄ Recall ‚Üì (on rate plus de d√©parts)

Si on baisse le seuil (ex: 0.5 ‚Üí 0.3) :
‚îú‚îÄ Precision ‚Üì (plus de fausses alarmes)
‚îî‚îÄ Recall ‚Üë (on d√©tecte plus de d√©parts)

Pour Salifort : Seuil = 0.3 (favorise le Recall)
```

---

## 4. Interpr√©tation Pratique pour le Projet Salifort {#interpretation}

### üéØ Sc√©nario d'utilisation mensuelle

**1. Ex√©cution du mod√®le**
```python
Janvier 2025 : 1500 employ√©s analys√©s
Pr√©dictions :
- 1425 employ√©s class√©s "restera" (score < 0.3)
- 75 employ√©s class√©s "√† risque" (score ‚â• 0.3)
```

**2. Interpr√©tation avec nos m√©triques**

**Precision = 94.6%** signifie :
- Sur les 75 employ√©s flagg√©s, environ **71 partiront vraiment**
- Seulement **4 fausses alarmes** (co√ªt : ~20 heures RH)

**Recall = 93.2%** signifie :
- Si 76 employ√©s partent r√©ellement ce mois-ci
- Le mod√®le en d√©tectera **71**
- Et en ratera **5** (co√ªt : 5 √ó 50K$ = 250K$)

**3. Action RH**

**Pour les 75 employ√©s √† risque :**
1. ‚úÖ **Intervention imm√©diate** : Entretien 1-on-1 avec manager
2. ‚úÖ **Analyse du score** :
   - Score 0.8-1.0 (tr√®s haut risque) ‚Üí Action urgente (promotion, ajustement salarial)
   - Score 0.5-0.8 (risque moyen) ‚Üí Plan de d√©veloppement
   - Score 0.3-0.5 (risque faible) ‚Üí Surveillance accrue

**ROI estim√© :**
- 71 d√©parts √©vit√©s √ó 50K$ = **$3.55M √©conomis√©s**
- 4 fausses alarmes √ó 5h RH √ó 50$/h = **$1,000 perdus**
- **ROI net = $3.549M par mois !**

### üìà Comparaison des 3 mod√®les

| Mod√®le | Precision | Recall | F1 | ROC-AUC | Meilleur pour... |
|--------|-----------|--------|----|---------|--------------------|
| **Gradient Boosting** | **95.1%** | **93.2%** | **94.2%** | **98.1%** | ‚≠ê **PRODUCTION** - Meilleur √©quilibre |
| Random Forest | **98.9%** | 92.7% | 95.7% | 97.8% | Minimiser fausses alarmes |
| Logistic Regression | 39.8% | **87.9%** | 54.8% | 87.2% | Baseline / Interpr√©tabilit√© |

### üéì Conclusion : Pourquoi le Gradient Boosting gagne ?

**1. ROC-AUC le plus √©lev√© (98.1%)**
- Meilleure capacit√© de discrimination globale

**2. Recall √©lev√© (93.2%)**
- Ne rate que 27 d√©parts sur 398 = $1.35M de pertes
- Alternative : Logistic Regression rate 48 d√©parts = $2.4M de pertes

**3. Precision excellente (95.1%)**
- Seulement 5% de fausses alarmes
- RH peut faire confiance aux pr√©dictions

**4. Robustesse**
- Validation crois√©e coh√©rente (92.7% recall en CV)
- Peu de sur-apprentissage

**5. Interpr√©tabilit√© suffisante**
- Feature importance disponible
- Permet d'identifier les leviers d'action

---

## üìö Ressources et R√©f√©rences

### Formules math√©matiques compl√®tes

```python
# M√©triques de base
Accuracy = (TP + TN) / (TP + TN + FP + FN)
Precision = TP / (TP + FP)
Recall = TP / (TP + FN)
F1-Score = 2 √ó (Precision √ó Recall) / (Precision + Recall)

# M√©triques avanc√©es
Specificity = TN / (TN + FP)  # Taux de vrais n√©gatifs
FPR = FP / (TN + FP)          # Taux de faux positifs
FNR = FN / (TP + FN)          # Taux de faux n√©gatifs

# ROC-AUC : Int√©grale de la courbe TPR vs FPR
ROC-AUC = ‚à´[0 to 1] TPR(FPR) d(FPR)
```

### Liens utiles
- [Scikit-learn - Classification Metrics](https://scikit-learn.org/stable/modules/model_evaluation.html)
- [Google ML Crash Course - ROC & AUC](https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc)
- [Confusion Matrix Explained](https://towardsdatascience.com/understanding-confusion-matrix-a9ad42dcfd62)

---

**Auteur** : Abdoulaye Leye
**Projet** : Salifort Motors HR Analytics
**Date** : Novembre 2025
**Certification** : Google Advanced Data Analytics
